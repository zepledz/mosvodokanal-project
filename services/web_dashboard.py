# web_dashboard.py
import os
from flask import Flask, render_template, jsonify, request
from flask_socketio import SocketIO
from confluent_kafka import Consumer, KafkaError
import json
import threading
import logging
from datetime import datetime, timedelta
import redis
from models import WaterMeasurement, BuildingStats, get_db, init_db, ITP, MKD
from sqlalchemy import desc, func
import time
from ml_predictor import initialize_ml_predictor, get_ml_predictor
from migrations import run_migrations
from flask_cors import CORS


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'mosvodokanal-secret-key-2024'

CORS(app,
     supports_credentials=True,
     origins=["http://localhost:5000", "http://localhost:3000", "http://127.0.0.1:5000"])

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
from auth import auth_bp, login_manager
login_manager.init_app(app)
app.register_blueprint(auth_bp)

socketio = SocketIO(app,
                   cors_allowed_origins="*",
                   async_mode='threading',
                   logger=True,
                   engineio_logger=True,
                   ping_timeout=60,
                   ping_interval=25)

redis_host = os.getenv('REDIS_HOST', 'redis')
kafka_bootstrap_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'kafka:9092')

redis_client = redis.Redis(host=redis_host, port=6379, decode_responses=True)

database_url = os.getenv('DATABASE_URL', 'postgresql://admin:password@postgres:5433/mosvodokanal')
initialize_ml_predictor(database_url)
run_migrations()

class DataProcessor:
    def __init__(self):
        logger.info(f"üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Kafka: {kafka_bootstrap_servers}")

        kafka_config = {
            'bootstrap.servers': kafka_bootstrap_servers,
            'group.id': 'web_dashboard_group',
            'auto.offset.reset': 'latest',
            'enable.auto.commit': True,
            'session.timeout.ms': 30000,
            'heartbeat.interval.ms': 10000,
        }

        try:
            self.kafka_consumer = Consumer(kafka_config)
            self.kafka_consumer.subscribe(['water_measurements'])
            logger.info("‚úÖ Kafka Consumer —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ –ø–æ–¥–ø–∏—Å–∞–Ω –Ω–∞ —Ç–æ–ø–∏–∫")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Kafka Consumer: {e}")
            self.kafka_consumer = None

        self.setup_database()

    def setup_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            init_db()
            logger.info("‚úÖ Web Dashboard: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå Web Dashboard: –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")

    def start_consuming(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Kafka"""
        if self.kafka_consumer:
            threading.Thread(target=self._consume_loop, daemon=True).start()
            logger.info("üöÄ –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å Kafka –∑–∞–ø—É—â–µ–Ω")
        else:
            logger.warning("‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å Kafka –Ω–µ –∑–∞–ø—É—â–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏")

    def _consume_loop(self):
        """–¶–∏–∫–ª –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ Kafka"""
        logger.info("üîÑ –ù–∞—á–∞–ª–æ —Ü–∏–∫–ª–∞ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è Kafka...")
        while True:
            try:
                if not self.kafka_consumer:
                    logger.error("‚ùå Kafka Consumer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                    time.sleep(5)
                    continue

                msg = self.kafka_consumer.poll(1.0)

                if msg is None:
                    continue
                if msg.error():
                    if msg.error().code() == KafkaError._PARTITION_EOF:
                        continue
                    else:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Kafka: {msg.error()}")
                        time.sleep(1)
                        continue

                try:
                    data = json.loads(msg.value().decode('utf-8'))
                    logger.info(f"üì® –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ Kafka: {data['building_id']}")

                    hvs_value = float(data['hvs_value'])
                    gvs_flow1_value = float(data['gvs_flow1_value'])
                    gvs_flow2_value = float(data['gvs_flow2_value'])
                    gvs_total = float(data['gvs_total'])

                    deviation, calculated_gvs_total = calculate_deviation(
                        hvs_value, gvs_flow1_value, gvs_flow2_value, "circulation"
                    )

                    status = "üö®" if deviation > 10 else "‚úÖ"
                    anomaly_type = ""
                    if deviation > 10:
                        if gvs_total > hvs_value:
                            anomaly_type = " (–í—ã—Å–æ–∫–æ–µ –ì–í–°)"
                        else:
                            anomaly_type = " (–í—ã—Å–æ–∫–æ–µ –•–í–°)"

                    processed_data = {
                        "address": data['address'],
                        "cold_water": hvs_value,
                        "hot_water": gvs_total,
                        "gvs_flow1": gvs_flow1_value,
                        "gvs_flow2": gvs_flow2_value,
                        "deviation": round(deviation, 2),
                        "status": status + anomaly_type,
                        "timestamp": data['timestamp'],
                        "building_id": data['building_id'],
                        "itp_id": data.get('itp_id', ''),
                        "device_id": data.get('device_id', ''),
                        "scenario": data['scenario']
                    }

                    socketio.emit('new_measurement', processed_data)
                    logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —á–µ—Ä–µ–∑ WebSocket: {data['building_id']}")

                    redis_key = f"last_measurement:{data['building_id']}"
                    redis_client.setex(redis_key, 300, json.dumps(processed_data))

                    logger.debug(f"üì• –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–º–µ—Ä–µ–Ω–∏–µ: {data['address']} | –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {deviation:.1f}%")

                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

            except Exception as e:
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è Kafka: {e}")
                time.sleep(5)

    def get_historical_data(self, limit=100):
        """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã"""
        db = next(get_db())
        try:
            measurements = db.query(WaterMeasurement).order_by(
                desc(WaterMeasurement.measurement_timestamp)
            ).limit(limit).all()

            historical_data = []
            for measurement in measurements:
                historical_data.append({
                    "address": measurement.address,
                    "cold_water": float(measurement.hvs_value),
                    "hot_water": float(measurement.gvs_total),
                    "gvs_flow1": float(measurement.gvs_flow1_value),
                    "gvs_flow2": float(measurement.gvs_flow2_value),
                    "deviation": float(measurement.deviation),
                    "status": "üö®" if measurement.is_anomaly else "‚úÖ",
                    "timestamp": measurement.measurement_timestamp.isoformat(),
                    "building_id": measurement.building_id,
                    "itp_id": measurement.itp_id if measurement.itp_id else "",
                    "device_id": measurement.device_id,
                    "scenario": measurement.scenario
                })
            return historical_data
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []
        finally:
            db.close()

    def get_database_stats(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        db = next(get_db())
        try:
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_measurements = db.query(WaterMeasurement).count()
            anomalies = db.query(WaterMeasurement).filter(WaterMeasurement.is_anomaly == True).count()
            total_buildings = db.query(BuildingStats).count()

            if total_measurements > 0:
                anomaly_percentage = (anomalies / total_measurements) * 100
            else:
                anomaly_percentage = 0

            return {
                "total_buildings": total_buildings,
                "total_measurements": total_measurements,
                "anomalies": anomalies,
                "normal": total_measurements - anomalies,
                "anomaly_percentage": round(anomaly_percentage, 1),
                "last_update": datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –±–∞–∑—ã: {e}")
            return {
                "total_buildings": 0,
                "total_measurements": 0,
                "anomalies": 0,
                "normal": 0,
                "anomaly_percentage": 0,
                "last_update": datetime.now().isoformat()
            }
        finally:
            db.close()

def calculate_deviation(hvs_flow_value, gvs_flow1_value, gvs_flow2_value, scheme_type="circulation"):
    """
    –†–∞—Å—á–µ—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó
    scheme_type: "circulation" (—Ü–∏—Ä–∫—É–ª—è—Ü–∏–æ–Ω–Ω–∞—è) –∏–ª–∏ "dead_end" (—Ç—É–ø–∏–∫–æ–≤–∞—è)
    """
    if scheme_type == "circulation":
        gvs_total = gvs_flow1_value - gvs_flow2_value
    else:
        gvs_total = gvs_flow1_value

    if hvs_flow_value > 0:
        deviation = abs((gvs_total - hvs_flow_value) / hvs_flow_value) * 100
    else:
        deviation = 0

    return deviation, gvs_total

def get_rule_based_predictions():
    """Rule-based –ø—Ä–æ–≥–Ω–æ–∑—ã –∫–∞–∫ fallback"""
    db = next(get_db())
    try:
        buildings = db.query(BuildingStats).order_by(
            desc(BuildingStats.last_measurement)
        ).all()

        predictions = []
        for building in buildings:
            latest_measurement = db.query(WaterMeasurement).filter(
                WaterMeasurement.building_id == building.building_id
            ).order_by(desc(WaterMeasurement.measurement_timestamp)).first()

            if latest_measurement:
                deviation = float(latest_measurement.deviation)
                risk_score = min(deviation / 50.0, 1.0)

                predictions.append({
                    "building_id": building.building_id,
                    "address": building.address,
                    "risk_score": round(risk_score, 3),
                    "risk_level": "–≤—ã—Å–æ–∫–∏–π" if risk_score > 0.7 else "—Å—Ä–µ–¥–Ω–∏–π" if risk_score > 0.3 else "–Ω–∏–∑–∫–∏–π",
                    "last_measurement": latest_measurement.measurement_timestamp.isoformat(),
                    "hvs_value": float(latest_measurement.hvs_value),
                    "gvs_value": float(latest_measurement.gvs_total),
                    "deviation": deviation,
                    "itp_id": building.itp_id
                })

        return jsonify({
            "predictions": predictions,
            "page": 1,
            "per_page": len(predictions),
            "total": len(predictions),
            "model_type": "rule_based_fallback"
        })
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ rule-based –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {e}")
        return jsonify({"predictions": [], "total": 0, "error": str(e)})
    finally:
        db.close()

def get_rule_based_risk_summary():
    """Rule-based —Å–≤–æ–¥–∫–∞ —Ä–∏—Å–∫–æ–≤ –∫–∞–∫ fallback"""
    db = next(get_db())
    try:
        buildings = db.query(BuildingStats).all()

        high_risk = 0
        medium_risk = 0
        low_risk = 0

        for building in buildings:
            latest = db.query(WaterMeasurement).filter(
                WaterMeasurement.building_id == building.building_id
            ).order_by(desc(WaterMeasurement.measurement_timestamp)).first()

            if latest:
                deviation = float(latest.deviation)
                risk_score = min(deviation / 50.0, 1.0)

                if risk_score > 0.7:
                    high_risk += 1
                elif risk_score > 0.3:
                    medium_risk += 1
                else:
                    low_risk += 1

        return jsonify({
            "high_risk_buildings": high_risk,
            "medium_risk_buildings": medium_risk,
            "low_risk_buildings": low_risk,
            "total_buildings": len(buildings),
            "timestamp": datetime.now().isoformat(),
            "model_type": "rule_based_fallback"
        })
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ rule-based —Å–≤–æ–¥–∫–∏: {e}")
        return debug_risk_summary()
    finally:
        db.close()

processor = None

def initialize_processor():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
    global processor
    try:
        processor = DataProcessor()
        processor.start_consuming()
        logger.info("‚úÖ DataProcessor —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DataProcessor: {e}")
        processor = None

# –í—Ä–µ–º–µ–Ω–Ω—ã–µ debug endpoints
@app.route('/api/debug/predictions')
def debug_predictions():
    """–í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞"""
    mock_data = {
        "predictions": [
            {
                "building_id": "bld_001",
                "address": "—É–ª. –¢–≤–µ—Ä—Å–∫–∞—è, –¥. 1",
                "risk_score": 0.85,
                "risk_level": "–≤—ã—Å–æ–∫–∏–π",
                "last_measurement": datetime.now().isoformat(),
                "hvs_value": 15.234,
                "gvs_value": 8.567,
                "deviation": 45.2
            },
            {
                "building_id": "bld_002",
                "address": "—É–ª. –ê—Ä–±–∞—Ç, –¥. 25",
                "risk_score": 0.45,
                "risk_level": "—Å—Ä–µ–¥–Ω–∏–π",
                "last_measurement": datetime.now().isoformat(),
                "hvs_value": 12.123,
                "gvs_value": 10.456,
                "deviation": 15.8
            },
            {
                "building_id": "bld_003",
                "address": "–ø—Ä. –ú–∏—Ä–∞, –¥. 10",
                "risk_score": 0.15,
                "risk_level": "–Ω–∏–∑–∫–∏–π",
                "last_measurement": datetime.now().isoformat(),
                "hvs_value": 9.876,
                "gvs_value": 9.123,
                "deviation": 5.2
            }
        ],
        "page": 1,
        "per_page": 10,
        "total": 3
    }
    return jsonify(mock_data)

@app.route('/api/force_save_model', methods=['POST'])
def force_save_model():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    try:
        ml_predictor = get_ml_predictor()
        if ml_predictor:
            success = ml_predictor.save_model()
            return jsonify({"status": "success" if success else "failed", "message": "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞" if success else "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å"})
        return jsonify({"status": "error", "message": "ML predictor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)})

@app.route('/api/debug/ml_status')
def debug_ml_status():
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ML –º–æ–¥–µ–ª–∏"""
    try:
        ml_predictor = get_ml_predictor()

        status = {
            "ml_predictor_exists": ml_predictor is not None,
            "model_type": "ML" if ml_predictor and ml_predictor.model != "simple_rule_based" else "rule_based",
            "model_object_type": str(type(ml_predictor.model)) if ml_predictor and ml_predictor.model else "None",
            "model_file_exists": False,
            "error": None
        }

        if ml_predictor and hasattr(ml_predictor, 'model_path'):
            status["model_file_exists"] = os.path.exists(ml_predictor.model_path)
            status["model_path"] = ml_predictor.model_path

        return jsonify(status)

    except Exception as e:
        return jsonify({"error": str(e)})
@app.route('/api/debug/risk_summary')
def debug_risk_summary():
    """–í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–≤–æ–¥–∫–∏ —Ä–∏—Å–∫–æ–≤"""
    mock_data = {
        "high_risk_buildings": 8,
        "medium_risk_buildings": 15,
        "low_risk_buildings": 27,
        "total_buildings": 50,
        "timestamp": datetime.now().isoformat()
    }
    return jsonify(mock_data)

@app.route('/api/predictions')
def get_all_predictions():
    """–ü—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –≤—Å–µ—Ö –∑–¥–∞–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ML –º–æ–¥–µ–ª–∏"""
    db = next(get_db())
    try:
        ml_predictor = get_ml_predictor()
        if not ml_predictor:
            logger.warning("ML predictor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º rule-based –ø–æ–¥—Ö–æ–¥")
            return get_rule_based_predictions()

        buildings = db.query(BuildingStats).order_by(
            desc(BuildingStats.last_measurement)
        ).all()

        predictions = []
        for building in buildings:
            latest_measurement = db.query(WaterMeasurement).filter(
                WaterMeasurement.building_id == building.building_id
            ).order_by(desc(WaterMeasurement.measurement_timestamp)).first()

            if latest_measurement:
                try:
                    risk_score = ml_predictor.predict_anomaly_risk({
                        'hvs_value': float(latest_measurement.hvs_value),
                        'gvs_value': float(latest_measurement.gvs_total),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º gvs_total
                        'deviation': float(latest_measurement.deviation),
                        'timestamp': latest_measurement.measurement_timestamp.isoformat(),
                        'building_id': building.building_id
                    })
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ ML –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è {building.building_id}, –∏—Å–ø–æ–ª—å–∑—É–µ–º rule-based: {e}")
                    risk_score = min(float(latest_measurement.deviation) / 50.0, 1.0)

                predictions.append({
                    "building_id": building.building_id,
                    "address": building.address,
                    "risk_score": round(risk_score, 3),
                    "risk_level": "–≤—ã—Å–æ–∫–∏–π" if risk_score > 0.7 else "—Å—Ä–µ–¥–Ω–∏–π" if risk_score > 0.3 else "–Ω–∏–∑–∫–∏–π",
                    "last_measurement": latest_measurement.measurement_timestamp.isoformat(),
                    "hvs_value": float(latest_measurement.hvs_value),
                    "gvs_value": float(latest_measurement.gvs_total),
                    "deviation": float(latest_measurement.deviation),
                    "itp_id": building.itp_id
                })

        return jsonify({
            "predictions": predictions,
            "page": 1,
            "per_page": len(predictions),
            "total": len(predictions),
            "model_type": "ml" if ml_predictor and ml_predictor.model != "simple_rule_based" else "rule_based"
        })

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {e}")
        return get_rule_based_predictions()
    finally:
        db.close()

@app.route('/api/risk_summary')
def get_risk_summary():
    """–°–≤–æ–¥–∫–∞ –ø–æ —Ä–∏—Å–∫–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ML –º–æ–¥–µ–ª–∏"""
    db = next(get_db())
    try:
        ml_predictor = get_ml_predictor()
        if not ml_predictor:
            logger.warning("ML predictor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º rule-based –ø–æ–¥—Ö–æ–¥")
            return get_rule_based_risk_summary()

        buildings = db.query(BuildingStats).all()

        high_risk = 0
        medium_risk = 0
        low_risk = 0

        for building in buildings:
            latest = db.query(WaterMeasurement).filter(
                WaterMeasurement.building_id == building.building_id
            ).order_by(desc(WaterMeasurement.measurement_timestamp)).first()

            if latest:
                try:
                    risk_score = ml_predictor.predict_anomaly_risk({
                        'hvs_value': float(latest.hvs_value),
                        'gvs_value': float(latest.gvs_total),
                        'deviation': float(latest.deviation),
                        'timestamp': latest.measurement_timestamp.isoformat(),
                        'building_id': building.building_id
                    })
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ ML –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è {building.building_id}, –∏—Å–ø–æ–ª—å–∑—É–µ–º rule-based: {e}")
                    risk_score = min(float(latest.deviation) / 50.0, 1.0)

                if risk_score > 0.7:
                    high_risk += 1
                elif risk_score > 0.3:
                    medium_risk += 1
                else:
                    low_risk += 1

        return jsonify({
            "high_risk_buildings": high_risk,
            "medium_risk_buildings": medium_risk,
            "low_risk_buildings": low_risk,
            "total_buildings": len(buildings),
            "timestamp": datetime.now().isoformat(),
            "model_type": "ml" if ml_predictor and ml_predictor.model != "simple_rule_based" else "rule_based"
        })

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–æ–¥–∫–∏ —Ä–∏—Å–∫–æ–≤: {e}")
        return get_rule_based_risk_summary()
    finally:
        db.close()

@app.route('/api/predictions/<building_id>')
def get_predictions(building_id):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –∑–¥–∞–Ω–∏—è"""
    db = next(get_db())
    try:
        ml_predictor = get_ml_predictor()
        if not ml_predictor:
            return jsonify({"error": "ML predictor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"})

        measurements = db.query(WaterMeasurement).filter(
            WaterMeasurement.building_id == building_id
        ).order_by(desc(WaterMeasurement.measurement_timestamp)).limit(100).all()

        if not measurements:
            return jsonify({"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞"})

        latest = measurements[0]
        risk_score = ml_predictor.predict_anomaly_risk({
            'hvs_value': float(latest.hvs_value),
            'gvs_value': float(latest.gvs_total),
            'deviation': float(latest.deviation),
            'timestamp': latest.measurement_timestamp.isoformat(),
            'building_id': latest.building_id
        })

        recommendation = generate_recommendation(risk_score, latest)

        return jsonify({
            "building_id": building_id,
            "risk_score": round(risk_score, 3),
            "risk_level": "–≤—ã—Å–æ–∫–∏–π" if risk_score > 0.7 else "—Å—Ä–µ–¥–Ω–∏–π" if risk_score > 0.3 else "–Ω–∏–∑–∫–∏–π",
            "recommendation": recommendation,
            "timestamp": datetime.now().isoformat()
        })

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return jsonify({"error": "–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"})
    finally:
        db.close()

def generate_recommendation(risk_score, measurement):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞"""
    if risk_score > 0.7:
        return "üö® –í–´–°–û–ö–ò–ô –†–ò–°–ö! –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ –≤–æ–∑–º–æ–∂–Ω–∞—è —É—Ç–µ—á–∫–∞"
    elif risk_score > 0.5:
        return "‚ö†Ô∏è –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π —Ä–∏—Å–∫. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å–∏–ª–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"
    elif measurement.deviation > 15:
        return "üìä –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –Ω–æ—Ä–º—É. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è"
    else:
        return "‚úÖ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —à—Ç–∞—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ"

@socketio.on('connect')
def handle_connect():
    logger.info('‚úÖ –ö–ª–∏–µ–Ω—Ç –ø–æ–¥–∫–ª—é—á–∏–ª—Å—è —á–µ—Ä–µ–∑ WebSocket')
    try:
        keys = redis_client.keys('last_measurement:*')
        for key in keys[-10:]:
            data = redis_client.get(key)
            if data:
                socketio.emit('new_measurement', json.loads(data))
        logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {len(keys[-10:])} –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π –Ω–æ–≤–æ–º—É –∫–ª–∏–µ–Ω—Ç—É")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")

@socketio.on('disconnect')
def handle_disconnect():
    logger.info('‚ùå –ö–ª–∏–µ–Ω—Ç –æ—Ç–∫–ª—é—á–∏–ª—Å—è –æ—Ç WebSocket')

@app.route('/api/buildings')
def get_buildings():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∑–¥–∞–Ω–∏–π"""
    db = next(get_db())
    try:
        buildings = db.query(BuildingStats).all()

        building_list = []
        for building in buildings:
            building_data = {
                "building_id": building.building_id,
                "address": building.address,
                "itp_id": getattr(building, 'itp_id', 'N/A'),
                "total_measurements": building.total_measurements,
                "anomaly_count": building.anomaly_count,
                "anomaly_percentage": round((building.anomaly_count / building.total_measurements * 100), 1) if building.total_measurements > 0 else 0,
                "last_measurement": building.last_measurement.isoformat() if building.last_measurement else None
            }
            building_list.append(building_data)

        return jsonify(building_list)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∑–¥–∞–Ω–∏–π: {e}")
        return jsonify([])
    finally:
        db.close()

@app.route('/api/train_model', methods=['GET', 'POST'])
def train_model():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏"""
    try:
        ml_predictor = get_ml_predictor()
        if not ml_predictor:
            return jsonify({"status": "error", "message": "ML predictor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"})

        success = ml_predictor.train_model()

        if success:
            model_type = "ML" if ml_predictor.model != "simple_rule_based" else "rule-based"
            return jsonify({
                "status": "success",
                "message": f"–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ ({model_type})",
                "model_type": model_type
            })
        else:
            return jsonify({"status": "error", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"})

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        return jsonify({"status": "error", "message": str(e)})

@app.route('/api/model_status')
def model_status():
    """–°—Ç–∞—Ç—É—Å ML –º–æ–¥–µ–ª–∏"""
    ml_predictor = get_ml_predictor()
    status = {
        "initialized": ml_predictor is not None,
        "model_trained": ml_predictor is not None and ml_predictor.model is not None,
        "timestamp": datetime.now().isoformat()
    }
    return jsonify(status)

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return render_template('index.html')

@app.route('/api/stats')
def get_stats():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    if processor:
        stats = processor.get_database_stats()
        return jsonify(stats)
    else:
        return jsonify({
            "error": "DataProcessor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
            "total_buildings": 0,
            "total_measurements": 0,
            "anomalies": 0,
            "normal": 0,
            "anomaly_percentage": 0,
            "last_update": datetime.now().isoformat()
        })

@app.route('/api/historical')
def get_historical_data():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    limit = request.args.get('limit', 100, type=int)
    if processor:
        historical_data = processor.get_historical_data(limit)
        return jsonify(historical_data)
    else:
        return jsonify([])

@app.route('/api/measurements/<building_id>')
def get_building_measurements(building_id):
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑–º–µ—Ä–µ–Ω–∏–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–¥–∞–Ω–∏—è"""
    db = next(get_db())
    try:
        limit = request.args.get('limit', 50, type=int)
        measurements = db.query(WaterMeasurement).filter(
            WaterMeasurement.building_id == building_id
        ).order_by(desc(WaterMeasurement.measurement_timestamp)).limit(limit).all()

        measurement_list = []
        for measurement in measurements:
            measurement_list.append({
                "timestamp": measurement.measurement_timestamp.isoformat(),
                "hvs_value": float(measurement.hvs_value),
                "gvs_flow1_value": float(measurement.gvs_flow1_value),
                "gvs_flow2_value": float(measurement.gvs_flow2_value),
                "gvs_total": float(measurement.gvs_total),
                "deviation": float(measurement.deviation),
                "is_anomaly": measurement.is_anomaly,
                "scenario": measurement.scenario
            })

        return jsonify(measurement_list)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑–º–µ—Ä–µ–Ω–∏–π –∑–¥–∞–Ω–∏—è: {e}")
        return jsonify([])
    finally:
        db.close()

@app.route('/health')
def health_check():
    """Health check endpoint"""
    status = {
        "status": "healthy",
        "kafka_connected": processor is not None and processor.kafka_consumer is not None,
        "database_connected": True,
        "redis_connected": redis_client.ping() if redis_client else False,
        "timestamp": datetime.now().isoformat()
    }
    return jsonify(status)

@app.route('/api/charts/consumption')
def get_consumption_chart():
    """–î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è"""
    db = next(get_db())
    try:
        period = request.args.get('period', 30, type=int)
        building_id = request.args.get('building_id', 'all')

        query = db.query(WaterMeasurement)

        start_date = datetime.now() - timedelta(days=period)
        query = query.filter(WaterMeasurement.measurement_timestamp >= start_date)

        if building_id != 'all':
            query = query.filter(WaterMeasurement.building_id == building_id)

        measurements = query.all()

        if not measurements:
            return jsonify({"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥"})

        total_hvs = sum(float(m.hvs_value) for m in measurements)
        total_gvs = sum(float(m.gvs_total) for m in measurements)
        anomalies = sum(1 for m in measurements if m.is_anomaly)
        normal = len(measurements) - anomalies

        return jsonify({
            "consumption": {
                "hvs": round(total_hvs, 2),
                "gvs": round(total_gvs, 2)
            },
            "anomalies": {
                "anomalies": anomalies,
                "normal": normal,
                "total": len(measurements)
            }
        })

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")
        return jsonify({"error": "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"})
    finally:
        db.close()

@app.route('/api/charts/trend')
def get_trend_chart():
    """–î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ —Ç—Ä–µ–Ω–¥–∞"""
    db = next(get_db())
    try:
        period = request.args.get('period', 30, type=int)
        building_id = request.args.get('building_id', 'all')

        dates = []
        for i in range(period, 0, -1):
            date = datetime.now() - timedelta(days=i)
            dates.append(date.strftime('%Y-%m-%d'))

        daily_data = []

        for single_date in [(datetime.now() - timedelta(days=i)) for i in range(period, 0, -1)]:
            next_date = single_date + timedelta(days=1)

            query = db.query(WaterMeasurement).filter(
                WaterMeasurement.measurement_timestamp >= single_date,
                WaterMeasurement.measurement_timestamp < next_date
            )

            if building_id != 'all':
                query = query.filter(WaterMeasurement.building_id == building_id)

            measurements = query.all()

            day_hvs = sum(float(m.hvs_value) for m in measurements)
            day_gvs = sum(float(m.gvs_total) for m in measurements)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º gvs_total
            day_anomalies = sum(1 for m in measurements if m.is_anomaly)

            daily_data.append({
                "date": single_date.strftime('%m-%d'),
                "hvs": round(day_hvs, 2),
                "gvs": round(day_gvs, 2),
                "anomalies": day_anomalies
            })

        return jsonify({"daily_data": daily_data})

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        return jsonify({"error": "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"})
    finally:
        db.close()

@app.route('/api/charts/buildings')
def get_buildings_for_charts():
    """–°–ø–∏—Å–æ–∫ –∑–¥–∞–Ω–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
    db = next(get_db())
    try:
        buildings = db.query(BuildingStats).all()

        building_list = [{"id": "all", "address": "–í—Å–µ –∑–¥–∞–Ω–∏—è"}]
        for building in buildings:
            building_list.append({
                "id": building.building_id,
                "address": building.address
            })

        return jsonify({"buildings": building_list})

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∑–¥–∞–Ω–∏–π: {e}")
        return jsonify({"error": "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"})
    finally:
        db.close()

@app.route('/api/itp')
def get_itp_list():
    """–°–ø–∏—Å–æ–∫ –ò–¢–ü"""
    db = next(get_db())
    try:
        itp_list = db.query(ITP).all()
        return jsonify([{
            "itp_id": itp.itp_id,
            "itp_number": itp.itp_number,
            "created_at": itp.created_at.isoformat()
        } for itp in itp_list])
    except Exception as e:
        return jsonify({"error": str(e)})
    finally:
        db.close()

@app.route('/api/mkd')
def get_mkd_list():
    """–°–ø–∏—Å–æ–∫ –ú–ö–î —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –ò–¢–ü"""
    db = next(get_db())
    try:
        mkd_list = db.query(MKD).all()
        return jsonify([{
            "building_id": mkd.building_id,
            "address": mkd.address,
            "fias": mkd.fias,
            "unom": mkd.unom,
            "itp_id": mkd.itp_id
        } for mkd in mkd_list])
    except Exception as e:
        return jsonify({"error": str(e)})
    finally:
        db.close()

@app.route('/api/charts/risks')
def get_risk_chart():
    db = next(get_db())
    try:
        buildings = db.query(BuildingStats).limit(10).all()

        risk_data = []

        for building in buildings:
            latest = db.query(WaterMeasurement).filter(
                WaterMeasurement.building_id == building.building_id
            ).order_by(desc(WaterMeasurement.measurement_timestamp)).first()

            if latest:
                risk_level = min(float(latest.deviation) / 50.0, 1.0)
                risk_category = "–≤—ã—Å–æ–∫–∏–π" if risk_level > 0.7 else "—Å—Ä–µ–¥–Ω–∏–π" if risk_level > 0.3 else "–Ω–∏–∑–∫–∏–π"

                risk_data.append({
                    "address": building.address[:20] + "..." if len(building.address) > 20 else building.address,
                    "risk_score": round(risk_level * 100, 1),
                    "risk_category": risk_category,
                    "consumption": float(latest.hvs_value) + float(latest.gvs_total)
                })

        return jsonify({"risk_data": risk_data})

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤: {e}")
        return jsonify({"error": "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"})
    finally:
        db.close()


@app.route('/api/debug/save_model', methods=['POST'])
def debug_save_model():
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
    try:
        ml_predictor = get_ml_predictor()
        if not ml_predictor:
            return jsonify({"error": "ML predictor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"})

        success = False
        if hasattr(ml_predictor, 'save_model'):
            success = ml_predictor.save_model()
            return jsonify({
                "status": "success" if success else "failed",
                "has_save_method": True,
                "model_type": str(type(ml_predictor.model)),
                "model_is_none": ml_predictor.model is None
            })
        else:
            return jsonify({
                "status": "error",
                "has_save_method": False,
                "message": "–ú–µ—Ç–æ–¥ save_model –Ω–µ –Ω–∞–π–¥–µ–Ω"
            })
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)})


@app.route('/api/debug/model_info')
def debug_model_info():
    """–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    try:
        ml_predictor = get_ml_predictor()
        if not ml_predictor:
            return jsonify({"error": "ML predictor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"})

        return jsonify({
            "model_exists": ml_predictor.model is not None,
            "model_type": str(type(ml_predictor.model)),
            "model_attributes": dir(ml_predictor.model) if ml_predictor.model else [],
            "has_save_method": hasattr(ml_predictor, 'save_model'),
            "model_path": getattr(ml_predictor, 'model_path', 'unknown')
        })
    except Exception as e:
        return jsonify({"error": str(e)})

if __name__ == '__main__':
    initialize_processor()

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –ø–æ—Ä—Ç—É 5000...")
    try:
        socketio.run(app,
                    host='0.0.0.0',
                    port=5000,
                    debug=False,
                    allow_unsafe_werkzeug=True)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {e}")